{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Rules:\n",
      "Rule 1: a + m -> am\n",
      "Rule 2: am + </w> -> am</w>\n",
      "Rule 3: I + </w> -> I</w>\n",
      "Rule 4: A + d -> Ad\n",
      "Rule 5: Ad + am</w> -> Adam</w>\n",
      "[('a', 'm'), ('am', '</w>'), ('I', '</w>'), ('A', 'd'), ('Ad', 'am</w>')]\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "from collections import defaultdict \n",
    "\n",
    "# Function to get the statistics of the pairs of characters in the vocabulary\n",
    "def get_stats(vocab): \n",
    "    pairs = defaultdict(int) \n",
    "    for word, freq in vocab.items(): \n",
    "        symbols = word.split() \n",
    "        # Loop through each pair of characters in a word\n",
    "        for i in range(len(symbols)-1): \n",
    "            # Increment the count of the pair in the dictionary\n",
    "            pairs[symbols[i],symbols[i+1]] += freq \n",
    "    return pairs \n",
    "\n",
    "# Function to merge the most frequent pair in the vocabulary\n",
    "def merge_vocab(pair, v_in): \n",
    "    v_out = {} \n",
    "    bigram = re.escape(' '.join(pair)) \n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)') \n",
    "    for word in v_in: \n",
    "        # Replace the most frequent pair with the merged pair in each word\n",
    "        w_out = p.sub(''.join(pair), word) \n",
    "        v_out[w_out] = v_in[word] \n",
    "    return v_out \n",
    "\n",
    "# Function to generate the initial vocabulary from the input data\n",
    "def get_vocab(data): \n",
    "    vocab = defaultdict(int) \n",
    "    for line in data: \n",
    "        for word in line.split(): \n",
    "            # Split each word into characters and add the end-of-word token\n",
    "            vocab[' '.join(list(word)) + ' </w>'] += 1\n",
    "    return vocab \n",
    "\n",
    "# Main function to perform byte pair encoding\n",
    "def byte_pair_encoding(data, n): \n",
    "    # Generate the initial vocabulary\n",
    "    vocab = get_vocab(data) \n",
    "    rules = []\n",
    "    for i in range(n): \n",
    "        # Get the statistics of the pairs of characters\n",
    "        pairs = get_stats(vocab) \n",
    "        # Find the most frequent pair\n",
    "        best = max(pairs, key=pairs.get) \n",
    "        # Add the most frequent pair to the list of rules\n",
    "        rules.append(best)\n",
    "        # Merge the most frequent pair in the vocabulary\n",
    "        vocab = merge_vocab(best, vocab) \n",
    "    return vocab, rules\n",
    "\n",
    "# Example usage:\n",
    "# Define the input data and the number of iterations\n",
    "training_sentences = \"I am Adam\"\n",
    "training_data = training_sentences.split()\n",
    "num_iterations = 5\n",
    "\n",
    "# Perform byte pair encoding and print the generated rules\n",
    "vocab, rules = byte_pair_encoding(training_data, num_iterations)\n",
    "print(\"Generated Rules:\")\n",
    "for i, rule in enumerate(rules, start=1):\n",
    "    # Print each rule\n",
    "    print(f\"Rule {i}: {rule[0]} + {rule[1]} -> {rule[0]}{rule[1]}\")\n",
    "\n",
    "# Print the final list of rules\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided Python code is an implementation of Byte Pair Encoding (BPE), a form of tokenization that is used in natural language processing (NLP). The goal of BPE is to divide a piece of text into a set of common subwords, which can be useful for handling words that are not in the dictionary, among other things.\n",
    "\n",
    "The code defines several functions:\n",
    "\n",
    "1. `get_stats(vocab)`: This function calculates the frequency of each pair of consecutive characters in the given vocabulary. It uses a [`defaultdict`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fcollections%2F__init__.pyi%22%2C%22defaultdict%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/collections/__init__.pyi\") to store the pairs as keys and their frequencies as values. The [`defaultdict`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fcollections%2F__init__.pyi%22%2C%22defaultdict%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/collections/__init__.pyi\") is a dictionary subclass that calls a factory function to supply missing values, in this case, [`int`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22int%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"), which defaults to zero.\n",
    "\n",
    "2. `merge_vocab(pair, v_in)`: This function merges the most frequent pair of characters in the vocabulary. It uses regular expressions to find and replace the most frequent pair with the merged pair in each word.\n",
    "\n",
    "3. `get_vocab(data)`: This function generates the initial vocabulary from the input data. It splits each word into characters and adds an end-of-word token. The vocabulary is a [`defaultdict`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fcollections%2F__init__.pyi%22%2C%22defaultdict%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/collections/__init__.pyi\") where the keys are the words (with characters separated by spaces and an end-of-word token at the end) and the values are the frequencies of the words.\n",
    "\n",
    "4. `byte_pair_encoding(data, n)`: This is the main function that performs the BPE. It first generates the initial vocabulary using the `get_vocab` function. Then, for [`n`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fcollections%2F__init__.pyi%22%2C%22n%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/collections/__init__.pyi\") iterations, it gets the statistics of the pairs of characters using the `get_stats` function, finds the most frequent pair, adds it to the list of rules, and merges it in the vocabulary using the `merge_vocab` function.\n",
    "\n",
    "The code also includes an example usage of the BPE implementation. It defines the input data and the number of iterations, performs the BPE, and prints the generated rules and the final list of rules.\n",
    "\n",
    "The code uses several built-in Python functions and methods, such as [`len`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22len%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"), [`escape`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fre.pyi%22%2C%22escape%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/re.pyi\"), [`join`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22join%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"), [`compile`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22compile%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"), and [`sub`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fcollections%2F__init__.pyi%22%2C%22sub%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/collections/__init__.pyi\"), and several built-in Python classes, such as [`defaultdict`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fcollections%2F__init__.pyi%22%2C%22defaultdict%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/collections/__init__.pyi\"), [`range`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22range%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"), [`list`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22list%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"), and [`enumerate`](command:_github.copilot.openSymbolInFile?%5B%22c%3A%2FUsers%2Fijlal%2F.vscode%2Fextensions%2Fms-python.vscode-pylance-2024.3.1%2Fdist%2Ftypeshed-fallback%2Fstdlib%2Fbuiltins.pyi%22%2C%22enumerate%22%5D \"c:/Users/ijlal/.vscode/extensions/ms-python.vscode-pylance-2024.3.1/dist/typeshed-fallback/stdlib/builtins.pyi\"). These functions, methods, and classes are used to manipulate strings, lists, and dictionaries, to work with regular expressions, and to iterate over data, among other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Test Sentence: Adam Madam\n",
      "List of Subword Tokens: ['A', 'd', 'a', 'm', '</w>', 'M', 'a', 'd', 'a', 'm', '</w>']\n",
      "\n",
      "Applying Rule: a + m -> am\n",
      "Merged Tokens: ['A', 'd', 'am', '</w>', 'M', 'a', 'd', 'am', '</w>']\n",
      "\n",
      "Applying Rule: am + </w> -> am</w>\n",
      "Merged Tokens: ['A', 'd', 'am</w>', 'M', 'a', 'd', 'am</w>']\n",
      "\n",
      "Applying Rule: I + </w> -> I</w>\n",
      "Merged Tokens: ['A', 'd', 'am</w>', 'M', 'a', 'd', 'am</w>']\n",
      "\n",
      "Applying Rule: A + d -> Ad\n",
      "Merged Tokens: ['Ad', 'am</w>', 'M', 'a', 'd', 'am</w>']\n",
      "\n",
      "Applying Rule: Ad + am</w> -> Adam</w>\n",
      "Merged Tokens: ['Adam</w>', 'M', 'a', 'd', 'am</w>']\n",
      "\n",
      "Final List of Subword Tokens: ['Adam</w>', 'M', 'a', 'd', 'am</w>']\n"
     ]
    }
   ],
   "source": [
    "# Define a test sentence\n",
    "test_sentence = \"Adam Madam\"\n",
    "# Split the sentence into words\n",
    "words = test_sentence.split(' ')\n",
    "\n",
    "# Initialize an empty list to store the tokens\n",
    "tokens = []\n",
    "for word in words:\n",
    "    # For each word, split it into characters and add the end-of-word token\n",
    "    tokens += [char for char in list(word) + ['</w>']]\n",
    "\n",
    "# Print the original sentence and the list of tokens\n",
    "print(\"Original Test Sentence:\",test_sentence)\n",
    "print(\"List of Subword Tokens:\",tokens)\n",
    "print()\n",
    "\n",
    "# Function to apply the merging rules to a list of tokens\n",
    "def apply_rules(rules,tokens):\n",
    "    # Initialize the list of merged tokens as the original list of tokens\n",
    "    merged_tokens = tokens\n",
    "    # Loop through each rule\n",
    "    for rule in rules:\n",
    "        # Loop through each pair of tokens in the list\n",
    "        for i in range(len(merged_tokens)-1):\n",
    "            # If the pair of tokens matches the rule, merge them\n",
    "            if merged_tokens[i] == rule[0] and merged_tokens[i+1] == rule[1]:\n",
    "                merged_tokens[i] = rule[0] + rule[1]\n",
    "                merged_tokens[i+1] = \"\"\n",
    "        # Remove the empty tokens\n",
    "        merged_tokens = [token for token in merged_tokens if token != \"\"]\n",
    "        # Print the rule and the list of merged tokens\n",
    "        print(f\"Applying Rule: {rule[0]} + {rule[1]} -> {rule[0]}{rule[1]}\")\n",
    "        print(\"Merged Tokens:\",merged_tokens)\n",
    "        print()\n",
    "    # Return the final list of merged tokens\n",
    "    return merged_tokens\n",
    "\n",
    "# Apply the rules to the list of tokens\n",
    "new_tokens = apply_rules(rules,tokens)\n",
    "\n",
    "# Print the final list of subword tokens\n",
    "print(\"Final List of Subword Tokens:\",new_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script is implementing a basic version of Byte Pair Encoding (BPE), a subword tokenization algorithm that is used in natural language processing (NLP). The goal of BPE is to divide words into smaller units (subwords or characters) that occur frequently across the corpus.\n",
    "\n",
    "The script starts by defining a test sentence \"Adam Madam\". It then splits the sentence into words using the `split(' ')` function, which splits a string into a list of words based on the provided separator (a space in this case).\n",
    "\n",
    "Next, it initializes an empty list `tokens` to store the tokens. For each word in the list of words, it splits the word into characters and adds an end-of-word token `</w>`. This is done using a list comprehension that iterates over each character in the word and the end-of-word token, adding each one to the `tokens` list.\n",
    "\n",
    "The script then prints the original sentence and the list of tokens.\n",
    "\n",
    "The `apply_rules` function is defined to apply the merging rules to a list of tokens. It takes two arguments: `rules` and `tokens`. `rules` is a list of pairs of characters that should be merged, and `tokens` is the list of tokens to which the rules should be applied.\n",
    "\n",
    "The function starts by initializing `merged_tokens` as a copy of `tokens`. It then loops over each rule in `rules`. For each rule, it loops over each pair of tokens in `merged_tokens`. If a pair of tokens matches the rule, it merges them by concatenating the two tokens and replacing the second token with an empty string. After all pairs have been checked for a rule, it removes the empty tokens from `merged_tokens`.\n",
    "\n",
    "The function then prints the rule that was applied and the list of merged tokens after applying the rule. It does this for each rule in `rules`.\n",
    "\n",
    "Finally, the function returns the final list of merged tokens after all rules have been applied.\n",
    "\n",
    "The script then applies the rules to the list of tokens using the `apply_rules` function and prints the final list of subword tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
